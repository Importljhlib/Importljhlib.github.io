---
layout: post
title: "ResNet : Deep Residual Learning for Image Recognition"
date: 2025-03-03 01:53:00 + 0900
category: paper
---
# ResNet : Deep Residual Learning for Image Recognition

## Abstract

모델은 depth의 깊이에 따라서 성능에 큰 영향을 받게 된다. 하지만 depth가 증가함에 따라서 오버피팅, 기울기 소실, 그리고 파라미터 수의 증가에 따른 연산량 증가 등이 문제가 될 수 있다. 

depth는 visual recognition task에서 매우 중요한 부분인데, 이 논문에서 depth가 깊어질 수록 발생하는 문제에 대해서 residual learning framework를 제안하여 깊은 모델을 좀 더 효율적으로 학습 시키는 방법에 대해서 소개하고 있다.

## Introduction

![](/img/res1.png)

위 figure는 layer 수에 따른 “plain” networks의 training error와 test error를 나타낸 것이다. 

그래프를 봤을 때 네트워크가 깊어짐에 따라서 더 나쁜 성능을 보인다는 것을 알 수 있다. 이 문제의 원인은 training error도 test error와 함께 높아진 것을 보아 단순히 오버피팅의 문제가 아닌, layer의 수가 증가 때문이라는 것을 알 수 있다. 

즉, 최적화가 되지 않고 있는 것.

이를 해결하기 위한 방법으로 **Residual block**을 사용하는 것이다!

![](/img/res2.png)

![](/img/res3.png)

왼쪽의 그림은 우리가 알고있는 일반적인 네트워크이다. 기존의 네트워크는 입력 x를 받고 layer들을 거쳐서 출력 H(x)를 반환하게 된다. 

하지만 오른쪽 그림과 같은 Residual Learning을 하게 되면 출력값으로 H(x)가 아닌, 출력과 입력의 차인 **H(x) - x**를 얻고자 하는 것이다.

다시 설명하자면, 오른쪽 그림이 나타내는 수식은 **H(x) = F(x) + x**라고 할 수 있다. 이 수식의 의미는 x라는 기존에 학습한 정보를 H(x)에 보존하고, 거기에 추가적인 학습한 정보인 F(x)만을 학습하게 되는 것이다. 

따라서 많은 학습이 이루어 질수록 x는 점점 출력값인 H(x)에 근접하게 되고, 추가 학습량인 F(x)는 점점 작아져 최종적으로 0에 가까운 최소값으로 수렴되어야 한다.

잔차(residual)을 의미하는 H(x) - x를 최소화 시키는 것이 목표이므로 0 = H(x) - x, H(x) = x가 최적의 해이며, 따라서 H(x)를 x로 mapping하는 것이 이 방법의 최종적인 목표이다.

또한 이 방법은 단순히 입력에서 출력으로 연결되는 shortcut만 추가하면 되기 때문에 네트워크 구조를 크게 변경할 필요가 없다는 것이 장점이다.

## Deep Residual Learning

### Residual Learning

위의 설명과 같으므로 생략한다.

### Identity Mapping by Shortcut

![](/img/res4.png)

Residual Block은 Residual Mapping Funtion인 F와 입력 x의 합으로 이루어진 출력 y로 정의할 수 있다.

또한 F와 x의 차원이 다를 수 있기 때문에 아래와 같이 **Linear Projection**을 추가해줄 수도 있다.

![](/img/res5.png)

W_s라는 linear projection에 사용되는 matrix를 통해서 차원을 맞춰준다.

## Network Architectures

ResNet은 VGGNet을 기반으로 한다.

![](/img/res6.png)

가장 오른쪽 구조가 **Residual Network**이다.

보다싶이, Plain Network에 중간마다 Shortcut Connection을 추가한 형태이다.

이때 Input과 output의 차원이 다르다면 두 가지의 옵션이 있는데, 

첫 번째는 Identity Mapping을 그대로 진행한 뒤, zero padding을 사용하는 방법.

두 번째는 앞에서 설명한 Projection Shortcut을 사용하는 것이다. (1x1 convolution)

두 방법 모두 stride는 2이다.

### Implementation

- image를 짧은 쪽이 [256, 480] 사이로 random하게 resize를 한 후 224 x 224 size로 random하게 crop.
- Horizontal Flip으로 Data Augmentation 해준다.
- conv와 활성화 함수 사이에 BN(Batch Normalization)을 추가한다.
- Weight Initialization?
- SGD 사용
- 256 mini-batch
- 0.1 learning rate부터 시작하여 Error가 수렴할 때마다 10으로 나눠줌.
- Weight Decay = 0.0001
- Momentim = 0.9
- 60 x 10^4 iterations
- dropout 미사용

## Experiments

### ImageNet Classification

![](/img/res7.png)

ImageNet 데이터셋을 사용하여 실험을 진행하였다.

![](/img/res8.png)

 plain network에서는 34개의 layer를 가진 모델이 18개의 layer를 가진 모델보다 성능이 좋지 않았던 반면에, Residual network에서는 그 반대인 모습을 보이고 있다.

### Identity vs. Projection Shortcuts

차원 증가를 위해 zero padding 대신에, Projection하는 방법을 살펴보자.

A) Zero padding을 통해 차원을 증가

B) Projection을 통해 차원을 증가

C) 모든 Shortcut을 Projection

![](/img/res9.png)

성능은 C, B, A순으로 좋았지만 성능의 차이가 크지 않아서 필수적이지 않다고 한다.

또한 Identity shortcut는 bottleneck 구조의 복잡성을 높이지 않는 것에 매우 중요하기 때문이기도 하다.

### Deeper Bottleneck Architectures

![](/img/res10.png)

깊은 모델에서 학습 시간이 오래 걸린다는 문제를 해결하기 위해 Bottleneck 구조를 제안하였다. 

각 Residual Function을 2-layer 구조가 아닌 3-layer구조로, 1x1 - 3x3 - 1x1 convolution으로 구성하였다. 여기서 1x1 layer는 Didmension을 줄였다 키우는 역할을 하게 된다.

또한 Identity shortcut이 여기서 중요한 역할을 하는데, 만약 bottleneck 구조에서 Identity shortcut이 아닌 projection shortcut으로 대체된다면 시간 복잡도와 모델의 크기가 2배로 늘어난다고 한다.

즉, Identity shortcut이 Bottleneck 구조에서 더욱 효율적이다.