---
layout: post
title: "Adapt or Perish: Adaptive Sparse Transformer with Attention Feature Refinement for Image Restoration (CVPR 2024)"
date: 2025-03-26 01:53:00 + 0900
category: paper
---

## Introduction

기존의 Transformer의 attention 메커니즘은 관련 없는 영역에서 의도치 않게 노이즈가 발생하는 경우가 있었다.

또한 피처맵 내의 중복된 정보는 더 좋은 피처를 만드는 데에 있어서 방해가 될 수 있다.

이 논문에서는 이러한 문제에 대하여 더욱 효율적인 모델인 **Adaptive Sparse Transformer(AST)**를 제안하였다.

AST는 크게 두 가지의 주요 모듈을 가지고 있다.

- Adaptive Sparse Self-Attention block (ASSA)
    - sparse self-attention branch (SSA)
    - dense self-attention counterpart (DSA)
- Feature Refinement Feed-forward Network (FRFN)

![](/img/AST/image.png)

## Related Work

CNN은 receptive field 이슈.

기존의 vanilla Self-Attention의 복잡도 문제 (O(N^2))

window-based attention은 복잡도를 O(WN)으로 낮춤..

## Proposed Method

![](/img/AST/image%201.png)

### Overall Pipeline

가장 먼저 H x W x 3 차원의 이미지 I가 입력으로 들어가게 된다.

처음으로 conv layer를 지나가게 되는데, 이는 low-level feature representaion인 F_0을 생성하게 된다.

그 후에는 Encoder를 지나치게 되는데, FRFN 블럭과 conv로 이루어져 있다. 이때의 conv는 down-sampling을 위한 것이다.

Decoder에는 ASSA, FRFN, 그리고 conv를 포함하고 있다. 이때의 conv layer는 up-sampling을 위한 것이다.

또한 bottleneck은 Decoder와 똑같은 구조로 앞에 배치 되어있다.

마지막으로 conv layer가 H x W x 3차원인 residual image R을 만들어 $\hat{I} = I + R$ 을 만들어내게 된다. 그리고 loss 함수는 다음과 같이 정의된다.

$$
\mathcal{L}(I', \hat{I}) = \sqrt{\|I' - \hat{I}\|^2 + \epsilon^2}

$$

### AST Block Design

**Adaptive Sparse Self-Attention**

기존의 vanilla Transformer의 한계점은 모든 토큰을 고려한다는 점이다. 따라서 불필요한 영역의 계산이 포함될 수 있다는 점. 추가로 중복된 피처 또한 포함될 수 있었다. 

이를 해결하기 위해 이 논문에선 첫번째로 squared ReLU 기반인 **Sparse Self-Attention 메커니즘(SSA)**을 제안하였다. 

$$
SSA = ReLU^2(QK^T/\sqrt{d}+B)
$$

또한 ReLU 기반 self attention의 지나친 sparsity를 고려하여 softmax를 도입한 **Dense Self-Attention(DSA)**를 사용하여 중요한 정보를 유지하게 하였다.

$$
DSA = SoftMax(QK^T/\sqrt{d}+B)
$$

즉, 두 개의 브랜치를 통해서 노이즈 및 중복되는 정보를 줄이면서 적절한 정보를 유지하는 것.

그리고 마지막으로 Attention score는 다음과 같이 계산된다.

$$
A = (w_1 * SSA + w_2 * DSA)V
$$

여기서 w1과 w2는 두 개의 브랜치를 adaptive하게 변화시키기 위한 정규화된 가중치이다.

**Feature Refinement Feed-forward Network**

중복 정보를 제거하기 위해서 ASSA를 채택하였음에도 채널에는 여전히 중복성이 남아있었다고 한다. 그래서 이 논문에서는 PConv 연산을 선택하였다고 한다. FRFN은 다음과 같이 나타낼 수 있다.

 

![](/img/AST/image%202.png)

W1, W2는 linear projections, [,]는 chanel-wise slice operation.

R()과 F()는 시퀀스 입력을 2D 피처맵으로 변환하는 reshape과 flatten 연산이다. 이는 아키텍쳐에 locality를 도입하는 데에 중요한 역할을 한다. 

마지막으로 PConv()와 DWConv()는 각각 partial convolution과 depth-wise convolution을 뜻한다.

## Experiments

평가 항목으로 PSNR과 SSIM 그리고 NIQE 방식을 사용하였다.

Rain Streak Removal, RainDrop Removal, Real Haze Removal tasks에 대하여 성능 측정을 진행하였다.

각 항목에 대한 실험 결과는 다음과 같다.

![](/img/AST/image%203.png)

![](/img/AST/image%204.png)

### Analysis and Discussion

**Eiffectiveness of adaptive architecture design**

다음은 ASSA와 다른 Attention 기법들을 비교한 실험 결과이다.

![](/img/AST/image%205.png)

Swin Self-Attention, Top-k Self-Attention 그리고 Condensed Self-Attention들과 비교했는데, PSNR에서 45.43 dB를 기록하면서 가장 좋은 성능을 보여주었다.

**Effectiveness of FRFN**

깊은 레이어에서 피처맵은 높은 차원의 채널을 가진다. 이에 따라 모든 피처 채널이 핵심 정보를 가지고 있지 않다.

이를 해결하기 위해서 FRFN을 적용한 것이다. 

![](/img/AST/image%206.png)

총 4개와 비교하여 실험을 진행하였다. 1) vanilla Feed-Forward Network (FFN), 2) Depth-wise convolution equipped Feed-forward Network (DFN), 3) Grated-Dconv Feed-forward Network (GDFN), 4) Locally-enhanced Feed-forward Network (LeFF), FRFN이 가장 높은 PSNR 수치를 기록하였다.

## Conclusions

이 논문의 목표는 가장 정보적인 표현들의 학습과 피처 내의 노이즈들을 제거를 adaptive하게 하여 깨끗한 이미지로 복구하는 것이었다. 이를 위해 adaptive architecture design, FRFN 등을 제안함으로써 removal task에서 성과를 거둘 수 있었다.

**Limitations**

![](/img/AST/image%207.png)

심한 화질 저하 이미지에서는 AST가 잘 처리하지 못하는 모습을 볼 수 있었다.