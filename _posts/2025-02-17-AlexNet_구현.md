---
layout: post
title: AlexNet 구현
date: 2025-02-17 01:53:00 + 0900
category: paper
---
# AlexNet 구현

### 데이터 불러오기

![](/img/ALimage.png)

CIFAR10 데이터셋 사용.

### 모델의 네트워크 클래스 구현

```
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt

class AlexNet(nn.Module):
  def __init__(self, num_classes = 10):
    super(AlexNet, self).__init__()
    self.features = nn.Sequential(
        nn.Conv2d(3, 96, kernel_size=11, stride = 4, padding = 2 ),
        nn.ReLU(inplace = True),
        nn.LocalResponseNorm(size = 5, alpha = 0.0001, beta = 0.75, k = 2),
        nn.MaxPool2d(kernel_size = 3, stride = 2),

        nn.Conv2d(96, 256, kernel_size = 5, stride = 1, padding = 2),
        nn.ReLU(inplace = True),
        nn.LocalResponseNorm(size = 5, alpha = 0.0001, beta = 0.75, k = 2),
        nn.MaxPool2d(kernel_size = 3, stride = 2),

        nn.Conv2d(256, 384, kernel_size = 3, stride = 1, padding = 1),
        nn.ReLU(inplace = True),

        nn.Conv2d(384, 384, kernel_size = 3, stride = 1, padding = 1),
        nn.ReLU(inplace = True),

        nn.Conv2d(384, 256, kernel_size = 3, stride = 1, padding = 1),
        nn.ReLU(inplace = True),
        nn.MaxPool2d(kernel_size = 3, stride = 2)
    )

    self.classifier = nn.Sequential(
        nn.Dropout(0.5),
        nn.Linear(6 * 6 * 256, 4096),
        nn.ReLU(inplace = True),

        nn.Dropout(0.5),
        nn.Linear(4096, 4096),
        nn.ReLU(inplace = True),

        nn.Linear(4096, num_classes)
    )

  def forward(self, x):
    x = self.features(x)
    x = torch.flatten(x, 1)
    x = self.classifier(x)
    return x

  def _initialize_weights(self):
    for layer in self.modules():
      if isinstance(layer, nn.Conv2d):
        nn.init.normal_(layer.weight, mean = 0, std = 0.01)
        nn.init.constant_(layer.bias, 0)
    nn.init.constant_(self.features[4].bias, 1)
    nn.init.constant_(self.features[10].bias, 1)
    nn.init.constant_(self.features[12].bias, 1)
```

![](/img/ALimage1.png)

### 모델 요약

![image.png](/img/ALimage2.png)

### 모델 학습

```python
from tqdm import tqdm

num_epochs = 10

train_losses = []
val_losses = []
val_accuracies = []

for epoch in range(num_epochs):
  model.train()
  running_loss = 0.0

  for images, labels in tqdm(train_loader):
    images, labels = images.to(device), labels.to(device)

    optimizer.zero_grad()
    outputs = model(images)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()

    running_loss += loss.item()

  train_loss = running_loss / len(train_loader)
  train_losses.append(train_loss)

  model.eval()
  val_loss = 0.0
  correct = 0
  total = 0

  with torch.no_grad():
    for images, labels in val_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        loss = criterion(outputs, labels)
        val_loss += loss.item()

        _,predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

  val_accuracy = 100 * correct / total
  val_accuracies.append(val_accuracy)

  val_loss /= len(val_loader)
  val_losses.append(val_loss)

  print(f"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.2f}%")

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label="Train Loss", color='blue')
plt.plot(val_losses, label="Validation Loss", color='orange')
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Train & Validation Loss")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(val_accuracies, label="Validation Accuracy", color='green')
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Validation Accuracy")
plt.legend()

plt.show()
```

### 결과

![](/img/ALimage3.png)

![](/img/ALimage4.png)

![](/img/ALimage5.png)